Here we design a perceptron network for the logical AND function with binary inputs and bipolar targets, and then train this network.


The perceptron function written in the code is the same as the perceptron_for_AND function described earlier.


The rule for updating weights and bias has already uploaded.


(Assumptions : Set alpha to one, initial weights and bias to zero, and theta to 0.2)
